{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d83a5ba",
   "metadata": {},
   "source": [
    "### üìÑ TRABALHO DE CLASSIFICA√á√ÉO COM KNN\n",
    "\n",
    "**Professor:** Romuere Rodrigues Velosos e Silva\n",
    "\n",
    "**Equipe:**\n",
    "\n",
    "1. Iago Roberto\n",
    "\n",
    "2. Francinaldo Barbosa\n",
    "\n",
    "3. Cristina de Moura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30490f3f",
   "metadata": {},
   "source": [
    "### ETAPA 0: Importa√ß√£o das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5b795b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def moldura(texto: str):\n",
    "    largura = len(texto) + 4\n",
    "    print(\"+\" + \"-\" * (largura - 2) + \"+\")\n",
    "    print(\"| \" + texto.center(largura - 4) + \" |\")\n",
    "    print(\"+\" + \"-\" * (largura - 2) + \"+\")\n",
    "\n",
    "def add_linha(texto: str, largura_total: int = 90):\n",
    "    texto = texto.strip()\n",
    "    if len(texto) + 6 >= largura_total:\n",
    "        largura_total = len(texto) + 10 \n",
    "\n",
    "    largura_lados = (largura_total - len(texto) - 4) // 2\n",
    "    linha = \"-\" * largura_lados\n",
    "\n",
    "    if (largura_total - len(texto) - 4) % 2 != 0:\n",
    "        print(f\"\\n# {linha} {texto} {linha}- #\\n\")\n",
    "    else:\n",
    "        print(f\"\\n# {linha} {texto} {linha} #\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004193ed",
   "metadata": {},
   "source": [
    "### ETAPA 1: Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "683959cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "| Carregando os dados |\n",
      "+---------------------+\n",
      "Primeiras linhas do dataset:\n",
      " Age Gender Smoking Hx Smoking Hx Radiothreapy Thyroid Function        Physical Examination Adenopathy      Pathology    Focality Risk   T  N  M Stage      Response Recurred\n",
      "  27      F      No         No              No        Euthyroid  Single nodular goiter-left         No Micropapillary   Uni-Focal  Low T1a N0 M0     I Indeterminate       No\n",
      "  34      F      No        Yes              No        Euthyroid         Multinodular goiter         No Micropapillary   Uni-Focal  Low T1a N0 M0     I     Excellent       No\n",
      "  30      F      No         No              No        Euthyroid Single nodular goiter-right         No Micropapillary   Uni-Focal  Low T1a N0 M0     I     Excellent       No\n",
      "  62      F      No         No              No        Euthyroid Single nodular goiter-right         No Micropapillary   Uni-Focal  Low T1a N0 M0     I     Excellent       No\n",
      "  62      F      No         No              No        Euthyroid         Multinodular goiter         No Micropapillary Multi-Focal  Low T1a N0 M0     I     Excellent       No\n",
      "  52      M     Yes         No              No        Euthyroid         Multinodular goiter         No Micropapillary Multi-Focal  Low T1a N0 M0     I Indeterminate       No\n"
     ]
    }
   ],
   "source": [
    "# 1) Carregar os dados\n",
    "\n",
    "moldura(\"Carregando os dados\")\n",
    "\n",
    "fp = Path('data/Thyroid_Diff.csv')\n",
    "if not fp.exists():\n",
    "    raise FileNotFoundError(f\"Arquivo n√£o encontrado: {fp}. Coloque o CSV em data/ ou ajuste o caminho.\")\n",
    "\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "print(\"Primeiras linhas do dataset:\")\n",
    "print(df.head(6).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed2303",
   "metadata": {},
   "source": [
    "### ETAPA 2: Convertendo a coluna alvo para inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4aa0912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "| Convertendo a coluna alvo 'Recurred' para inteiros |\n",
      "+----------------------------------------------------+\n",
      "\n",
      "Valores √∫nicos na coluna Recurred: ['No', 'Yes']\n",
      "\n",
      "Tabela - antes e depois (primeiras 6 linhas):\n",
      "Recurred (orig)  Recurred (mapeado)\n",
      "             No                   0\n",
      "             No                   0\n",
      "             No                   0\n",
      "             No                   0\n",
      "             No                   0\n",
      "             No                   0\n"
     ]
    }
   ],
   "source": [
    "# 2) Convers√£o da √∫ltima coluna (categ√≥rica) para inteiros (0/1)\n",
    "\n",
    "moldura(\"Convertendo a coluna alvo 'Recurred' para inteiros\")\n",
    "\n",
    "if 'Recurred' not in df.columns:\n",
    "    # tentar localizar √∫ltima coluna\n",
    "    last_col = df.columns[-1]\n",
    "    df = df.rename(columns={last_col: 'Recurred'})\n",
    "\n",
    "# Mapeamento simples: No -> 0, Yes -> 1. Ajuste se existirem outros valores.\n",
    "unique_vals = df['Recurred'].unique().tolist()\n",
    "print('\\nValores √∫nicos na coluna Recurred:', unique_vals)\n",
    "\n",
    "mapping = {v: (1 if str(v).strip().lower() in ['yes', 'y', 'sim', 's', '1', 'true', 'TRUE'] else 0) for v in unique_vals}\n",
    "# Aplicar mapeamento (n√£o destrutivo)\n",
    "df['result'] = df['Recurred'].map(mapping)\n",
    "\n",
    "# Tabela antes e depois (curta)\n",
    "before = df[['Recurred']].head(6).rename(columns={'Recurred': 'Recurred (orig)'})\n",
    "after = df[['result']].head(6).rename(columns={'result': 'Recurred (mapeado)'})\n",
    "print('\\nTabela - antes e depois (primeiras 6 linhas):')\n",
    "print(pd.concat([before, after], axis=1).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcb85a",
   "metadata": {},
   "source": [
    "### ETAPA 1: Pr√©-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f70abd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "| Pr√©-processamento dos dados |\n",
      "+-----------------------------+\n",
      "\n",
      "Colunas num√©ricas detectadas: ['Age']\n",
      "Colunas categ√≥ricas detectadas: ['Gender', 'Smoking', 'Hx Smoking', 'Hx Radiothreapy', 'Thyroid Function', 'Physical Examination', 'Adenopathy', 'Pathology', 'Focality', 'Risk', 'T', 'N', 'M', 'Stage', 'Response']\n",
      "\n",
      "# ------------------------ Resumo do conjunto de dados processado ------------------------ #\n",
      "\n",
      "  Amostras: 383\n",
      "  Features: 55\n",
      "  Features utilizadas: ['Age', 'Gender_F', 'Gender_M', 'Smoking_No', 'Smoking_Yes', 'Hx Smoking_No', 'Hx Smoking_Yes', 'Hx Radiothreapy_No', 'Hx Radiothreapy_Yes', 'Thyroid Function_Clinical Hyperthyroidism', 'Thyroid Function_Clinical Hypothyroidism', 'Thyroid Function_Euthyroid', 'Thyroid Function_Subclinical Hyperthyroidism', 'Thyroid Function_Subclinical Hypothyroidism', 'Physical Examination_Diffuse goiter', 'Physical Examination_Multinodular goiter', 'Physical Examination_Normal', 'Physical Examination_Single nodular goiter-left', 'Physical Examination_Single nodular goiter-right', 'Adenopathy_Bilateral', 'Adenopathy_Extensive', 'Adenopathy_Left', 'Adenopathy_No', 'Adenopathy_Posterior', 'Adenopathy_Right', 'Pathology_Follicular', 'Pathology_Hurthel cell', 'Pathology_Micropapillary', 'Pathology_Papillary', 'Focality_Multi-Focal', 'Focality_Uni-Focal', 'Risk_High', 'Risk_Intermediate', 'Risk_Low', 'T_T1a', 'T_T1b', 'T_T2', 'T_T3a', 'T_T3b', 'T_T4a', 'T_T4b', 'N_N0', 'N_N1a', 'N_N1b', 'M_M0', 'M_M1', 'Stage_I', 'Stage_II', 'Stage_III', 'Stage_IVA', 'Stage_IVB', 'Response_Biochemical Incomplete', 'Response_Excellent', 'Response_Indeterminate', 'Response_Structural Incomplete']\n",
      "\n",
      "# ------------------------------- Distribui√ß√£o das classes ------------------------------- #\n",
      "\n",
      "result\n",
      "0    275\n",
      "1    108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) Pr√©-processamento: tratar datas, valores ausentes e codificar vari√°veis\n",
    "\n",
    "moldura(\"Pr√©-processamento dos dados\")\n",
    "\n",
    "# Detectar colunas num√©ricas e categ√≥ricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Excluir a coluna result das features\n",
    "if 'result' in numeric_cols:\n",
    "    numeric_cols.remove('result')\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if 'Recurred' in categorical_cols:\n",
    "    categorical_cols.remove('Recurred')\n",
    "\n",
    "print('\\nColunas num√©ricas detectadas:', numeric_cols)\n",
    "print('Colunas categ√≥ricas detectadas:', categorical_cols)\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "X_raw = df.drop(columns=['Recurred', 'result'])\n",
    "y = df['result'].copy()\n",
    "\n",
    "X_proc_array = preprocessor.fit_transform(X_raw)\n",
    "\n",
    "feature_names_num = numeric_cols\n",
    "\n",
    "try:\n",
    "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "except Exception:\n",
    "    cat_feature_names = []\n",
    "\n",
    "feature_names = feature_names_num + cat_feature_names\n",
    "\n",
    "\n",
    "df_processado = pd.DataFrame(X_proc_array, columns=feature_names)\n",
    "\n",
    "df_processado['result'] = y.values\n",
    "\n",
    "add_linha(\"Resumo do conjunto de dados processado\")\n",
    "print(f\"  Amostras: {df_processado.shape[0]}\")\n",
    "print(f\"  Features: {df_processado.shape[1] - 1}\")\n",
    "print(f\"  Features utilizadas: {list(df_processado.columns.drop('result'))}\")\n",
    "\n",
    "# Verificar distribui√ß√£o de classes e se h√° dados suficientes\n",
    "add_linha(\"Distribui√ß√£o das classes\")\n",
    "print(df_processado['result'].value_counts(dropna=False))\n",
    "\n",
    "n_samples = df_processado.shape[0]\n",
    "if n_samples < 30:\n",
    "    print('\\nAVISO: o conjunto possui menos de 30 amostras ‚Äî alguns m√©todos (LOOCV) podem ficar menos informativos ou ruidosos.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04eea81",
   "metadata": {},
   "source": [
    "### ETAPA 4: Divis√£o dos dados e encontrando o melhor valor para o KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1e2a592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "| Buscando o melhor valor de k para KNN e dividindo os dados |\n",
      "+------------------------------------------------------------+\n",
      "\n",
      "# ---------------------------------- Divis√£o dos dados ----------------------------------- #\n",
      "\n",
      "  Train: (267, 55)  Val: (39, 55)  Test: (77, 55)\n",
      "\n",
      "# -------------------------- Resultados (valida√ß√£o) ‚Äî top 10 ks -------------------------- #\n",
      "\n",
      " k  val_accuracy\n",
      " 1      0.974359\n",
      " 3      0.974359\n",
      " 4      0.948718\n",
      " 5      0.948718\n",
      " 6      0.948718\n",
      " 7      0.948718\n",
      " 8      0.948718\n",
      " 9      0.948718\n",
      "10      0.948718\n",
      "11      0.948718\n",
      "\n",
      "[AVISO] Melhor k encontrado foi 1 (pode causar overfitting). Usando o segundo melhor valor.\n",
      "\n",
      "Melhor k definido para o KNN: 3\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4) ENCONTRANDO MELHOR VALOR DE K\n",
    "# Dividir em treino+valida√ß√£o (80%) e teste (20%) e dentro do 80% dividir em treino (70% total) e valida√ß√£o (10% total)\n",
    "\n",
    "moldura(\"Buscando o melhor valor de k para KNN e dividindo os dados\")\n",
    "\n",
    "X = df_processado.drop('result', axis=1)\n",
    "y = df_processado['result']\n",
    "\n",
    "# Primeiro split: separar teste 20%\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "# Agora dividir X_rem (80%) em train(70%) e val(10%) == propor√ß√£o em rela√ß√£o ao rem: train_size = 0.875\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.875, stratify=y_rem, random_state=42)\n",
    "\n",
    "add_linha(\"Divis√£o dos dados\")\n",
    "print('  Train:', X_train.shape, ' Val:', X_val.shape, ' Test:', X_test.shape)\n",
    "\n",
    "# Normalizar (fit no train)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Buscar k em 1..30\n",
    "from tqdm import trange\n",
    "k_range = range(1, min(31, max(2, int(np.sqrt(X_train.shape[0]) * 5))))  # limite razo√°vel\n",
    "val_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    val_scores.append((k, acc))\n",
    "\n",
    "val_df = pd.DataFrame(val_scores, columns=['k', 'val_accuracy']).sort_values(['val_accuracy','k'], ascending=[False, True])\n",
    "add_linha(\"Resultados (valida√ß√£o) ‚Äî top 10 ks\")\n",
    "print(val_df.head(10).to_string(index=False))\n",
    "\n",
    "# Melhor k encontrado\n",
    "best_k = int(val_df.iloc[0]['k'])\n",
    "\n",
    "# Se o melhor k for 1, pegar o segundo melhor (se existir)\n",
    "if best_k == 1 and len(val_df) > 1:\n",
    "    print(f\"\\n[AVISO] Melhor k encontrado foi 1 (pode causar overfitting). Usando o segundo melhor valor.\")\n",
    "    best_k = int(val_df.iloc[1]['k'])\n",
    "\n",
    "print(f\"\\nMelhor k definido para o KNN: {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914ef94",
   "metadata": {},
   "source": [
    "### ETAPA 5: Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eb303498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "| HOLD-OUT (70/30) repetido 50x |\n",
      "+-------------------------------+\n",
      "\n",
      "# ----------------------------- Sum√°rio do Hold-out (50 rep) ----------------------------- #\n",
      "\n",
      "accuracy             0.9242 ¬± 0.0187\n",
      "f1                   0.9023 ¬± 0.0250\n",
      "precision            0.9189 ¬± 0.0251\n",
      "recall               0.8904 ¬± 0.0286\n",
      "kappa                0.8049 ¬± 0.0497\n"
     ]
    }
   ],
   "source": [
    "# 5) HOLD-OUT (70/30) repetido 50x\n",
    "\n",
    "moldura(\"HOLD-OUT (70/30) repetido 50x\")\n",
    "\n",
    "n_repeats = 50\n",
    "sss = StratifiedShuffleSplit(n_splits=n_repeats, test_size=0.3, random_state=42)\n",
    "metrics_hold = {'accuracy': [], 'f1': [], 'precision': [], 'recall': [], 'kappa': []}\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_tr_s = sc.fit_transform(X_tr)\n",
    "    X_te_s = sc.transform(X_te)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "    clf.fit(X_tr_s, y_tr)\n",
    "    y_pred = clf.predict(X_te_s)\n",
    "\n",
    "    metrics_hold['accuracy'].append(accuracy_score(y_te, y_pred))\n",
    "    metrics_hold['f1'].append(f1_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_hold['precision'].append(precision_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_hold['recall'].append(recall_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_hold['kappa'].append(cohen_kappa_score(y_te, y_pred))\n",
    "\n",
    "hold_summary = {m: (np.mean(vals), np.std(vals)) for m, vals in metrics_hold.items()}\n",
    "\n",
    "add_linha(\"Sum√°rio do Hold-out (50 rep)\")\n",
    "for m, (mu, sd) in hold_summary.items():\n",
    "    print(f\"{m:<20} {mu:.4f} ¬± {sd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06814c5e",
   "metadata": {},
   "source": [
    "### ETAPA 6: K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8ec42c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "| K-FOLD (5) |\n",
      "+------------+\n",
      "\n",
      "# -------------------------------- Sum√°rio do K-Fold (5) --------------------------------- #\n",
      "\n",
      "accuracy             0.9242 ¬± 0.0155\n",
      "f1                   0.9022 ¬± 0.0222\n",
      "precision            0.9235 ¬± 0.0230\n",
      "recall               0.8878 ¬± 0.0283\n",
      "kappa                0.8049 ¬± 0.0441\n"
     ]
    }
   ],
   "source": [
    "# 6) K-FOLD (5)\n",
    "\n",
    "moldura(\"K-FOLD (5)\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics_kfold = {m: [] for m in metrics_hold}\n",
    "\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_tr_s = sc.fit_transform(X_tr)\n",
    "    X_te_s = sc.transform(X_te)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "    clf.fit(X_tr_s, y_tr)\n",
    "    y_pred = clf.predict(X_te_s)\n",
    "\n",
    "    metrics_kfold['accuracy'].append(accuracy_score(y_te, y_pred))\n",
    "    metrics_kfold['f1'].append(f1_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_kfold['precision'].append(precision_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_kfold['recall'].append(recall_score(y_te, y_pred, average='macro', zero_division=0))\n",
    "    metrics_kfold['kappa'].append(cohen_kappa_score(y_te, y_pred))\n",
    "\n",
    "kfold_summary = {m: (np.mean(vals), np.std(vals)) for m, vals in metrics_kfold.items()}\n",
    "\n",
    "add_linha(\"Sum√°rio do K-Fold (5)\")\n",
    "for m, (mu, sd) in kfold_summary.items():\n",
    "    print(f\"{m:<20} {mu:.4f} ¬± {sd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badb0d2",
   "metadata": {},
   "source": [
    "### ETAPA 7: LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "93f0233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "| Leave-One-Out |\n",
      "+---------------+\n",
      "\n",
      "Executando Leave-One-Out (pode demorar)...\n",
      "\n",
      "# ------------------------------- Sum√°rio do Leave-One-Out ------------------------------- #\n",
      "\n",
      "accuracy             0.9243 ¬± 0.0000\n",
      "f1                   0.9028 ¬± 0.0000\n",
      "precision            0.9214 ¬± 0.0000\n",
      "recall               0.8882 ¬± 0.0000\n",
      "kappa                0.8059 ¬± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 7) Leave-Ove-Out\n",
    "\n",
    "moldura(\"Leave-One-Out\")\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "metrics_loo = []\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "print('\\nExecutando Leave-One-Out (pode demorar)...')\n",
    "\n",
    "iteracao = 0\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_tr_s = sc.fit_transform(X_tr)\n",
    "    X_te_s = sc.transform(X_te)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "    clf.fit(X_tr_s, y_tr)\n",
    "    y_pred = clf.predict(X_te_s)\n",
    "\n",
    "    y_true_all.append(y_te.values[0])\n",
    "    y_pred_all.append(y_pred[0])\n",
    "\n",
    "    iteracao += 1\n",
    "    if iteracao % 500 == 0:\n",
    "        print(f\"  Processadas {iteracao} amostras...\")\n",
    "\n",
    "# Calcular m√©tricas finais\n",
    "metrics_loo = {\n",
    "    'accuracy': accuracy_score(y_true_all, y_pred_all),\n",
    "    'f1': f1_score(y_true_all, y_pred_all, average='macro', zero_division=0),\n",
    "    'precision': precision_score(y_true_all, y_pred_all, average='macro', zero_division=0),\n",
    "    'recall': recall_score(y_true_all, y_pred_all, average='macro', zero_division=0),\n",
    "    'kappa': cohen_kappa_score(y_true_all, y_pred_all)\n",
    "}\n",
    "\n",
    "loo_summary = {m: (val, 0.0) for m, val in metrics_loo.items()}\n",
    "add_linha(\"Sum√°rio do Leave-One-Out\")\n",
    "for m, (mu, sd) in loo_summary.items():\n",
    "    print(f\"{m:<20} {mu:.4f} ¬± {sd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877e307",
   "metadata": {},
   "source": [
    "### ETAPA 8: Tabelas comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "| Comparativo entre m√©todos |\n",
      "+---------------------------+\n",
      "              Method             Accuracy             F1-score            Precision               Recall                Kappa\n",
      "   Hold-out (50 rep)      0.9242 ¬± 0.0187      0.9023 ¬± 0.0250      0.9189 ¬± 0.0251      0.8904 ¬± 0.0286      0.8049 ¬± 0.0497\n",
      "          K-Fold (5)      0.9242 ¬± 0.0155      0.9022 ¬± 0.0222      0.9235 ¬± 0.0230      0.8878 ¬± 0.0283      0.8049 ¬± 0.0441\n",
      "       Leave-One-Out      0.9243 ¬± 0.0000      0.9028 ¬± 0.0000      0.9214 ¬± 0.0000      0.8882 ¬± 0.0000      0.8059 ¬± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 8) Comparativo entre os 3 m√©todos em formato de tabela\n",
    "rows = []\n",
    "# Hold-out\n",
    "rows.append({\n",
    "    'method': 'Hold-out (50 rep)',\n",
    "    'accuracy_mean': hold_summary['accuracy'][0], 'accuracy_std': hold_summary['accuracy'][1],\n",
    "    'f1_mean': hold_summary['f1'][0], 'f1_std': hold_summary['f1'][1],\n",
    "    'precision_mean': hold_summary['precision'][0], 'precision_std': hold_summary['precision'][1],\n",
    "    'recall_mean': hold_summary['recall'][0], 'recall_std': hold_summary['recall'][1],\n",
    "    'kappa_mean': hold_summary['kappa'][0], 'kappa_std': hold_summary['kappa'][1]\n",
    "})\n",
    "\n",
    "# K-Fold\n",
    "rows.append({\n",
    "    'method': 'K-Fold (5)',\n",
    "    'accuracy_mean': kfold_summary['accuracy'][0], 'accuracy_std': kfold_summary['accuracy'][1],\n",
    "    'f1_mean': kfold_summary['f1'][0], 'f1_std': kfold_summary['f1'][1],\n",
    "    'precision_mean': kfold_summary['precision'][0], 'precision_std': kfold_summary['precision'][1],\n",
    "    'recall_mean': kfold_summary['recall'][0], 'recall_std': kfold_summary['recall'][1],\n",
    "    'kappa_mean': kfold_summary['kappa'][0], 'kappa_std': kfold_summary['kappa'][1]\n",
    "})\n",
    "\n",
    "# LOO\n",
    "rows.append({\n",
    "    'method': 'Leave-One-Out',\n",
    "    'accuracy_mean': loo_summary['accuracy'][0], 'accuracy_std': loo_summary['accuracy'][1],\n",
    "    'f1_mean': loo_summary['f1'][0], 'f1_std': loo_summary['f1'][1],\n",
    "    'precision_mean': loo_summary['precision'][0], 'precision_std': loo_summary['precision'][1],\n",
    "    'recall_mean': loo_summary['recall'][0], 'recall_std': loo_summary['recall'][1],\n",
    "    'kappa_mean': loo_summary['kappa'][0], 'kappa_std': loo_summary['kappa'][1]\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "# Formata√ß√£o de sa√≠da (mean ¬± std)\n",
    "def fmt(mean, sd):\n",
    "    return f\"{mean:.4f} ¬± {sd:.4f}\"\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    'Method': summary_df['method'],\n",
    "    'Accuracy': [fmt(r['accuracy_mean'], r['accuracy_std']) for _, r in summary_df.iterrows()],\n",
    "    'F1-score': [fmt(r['f1_mean'], r['f1_std']) for _, r in summary_df.iterrows()],\n",
    "    'Precision': [fmt(r['precision_mean'], r['precision_std']) for _, r in summary_df.iterrows()],\n",
    "    'Recall': [fmt(r['recall_mean'], r['recall_std']) for _, r in summary_df.iterrows()],\n",
    "    'Kappa': [fmt(r['kappa_mean'], r['kappa_std']) for _, r in summary_df.iterrows()]\n",
    "})\n",
    "\n",
    "moldura(\"Comparativo entre m√©todos\")\n",
    "print(out.to_string(index=False, col_space=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
